#!/usr/bin/env python3
"""
An√°lisis para optimizar experimento FLAN con ~10,000 episodios
Evaluaci√≥n de uso de GPU y distribuci√≥n eficiente
"""

import os
import sys
import json
import psutil
import subprocess
import platform
from typing import Dict, List, Tuple, Optional

def detect_gpu_capabilities():
    """Detecta capacidades de GPU disponibles en el sistema"""
    
    print("="*80)
    print("üîç DETECCI√ìN DE CAPACIDADES GPU")
    print("="*80)
    
    gpu_info = {
        'nvidia_available': False,
        'cuda_available': False,
        'mps_available': False,  # Metal Performance Shaders (macOS)
        'gpu_count': 0,
        'gpu_memory': [],
        'recommendations': []
    }
    
    # Detectar NVIDIA GPU (CUDA)
    try:
        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            gpu_info['nvidia_available'] = True
            gpu_lines = result.stdout.strip().split('\n')
            gpu_info['gpu_count'] = len(gpu_lines)
            
            for line in gpu_lines:
                if line.strip():
                    name, memory = line.split(',')
                    gpu_info['gpu_memory'].append({
                        'name': name.strip(),
                        'memory_mb': int(memory.strip())
                    })
            
            print(f"‚úÖ NVIDIA GPU detectada:")
            for i, gpu in enumerate(gpu_info['gpu_memory']):
                print(f"   GPU {i}: {gpu['name']} - {gpu['memory_mb']:,} MB")
        else:
            print("‚ùå nvidia-smi no encontrado o fall√≥")
            
    except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):
        print("‚ùå NVIDIA GPU no detectada")
    
    # Detectar CUDA
    try:
        import torch
        if torch.cuda.is_available():
            gpu_info['cuda_available'] = True
            cuda_count = torch.cuda.device_count()
            print(f"‚úÖ CUDA disponible con {cuda_count} dispositivos")
            
            for i in range(cuda_count):
                props = torch.cuda.get_device_properties(i)
                print(f"   CUDA {i}: {props.name} - {props.total_memory // 1024**2:,} MB")
        else:
            print("‚ùå CUDA no disponible en PyTorch")
    except ImportError:
        print("‚ùå PyTorch no instalado")
    
    # Detectar Metal Performance Shaders (macOS)
    if platform.system() == "Darwin":  # macOS
        try:
            import torch
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                gpu_info['mps_available'] = True
                print("‚úÖ Metal Performance Shaders (MPS) disponible")
                gpu_info['recommendations'].append("Usar MPS para aceleraci√≥n en macOS")
            else:
                print("‚ùå MPS no disponible")
        except ImportError:
            print("‚ùå PyTorch no instalado - no se puede verificar MPS")
    
    # Generar recomendaciones
    if gpu_info['nvidia_available'] or gpu_info['cuda_available']:
        gpu_info['recommendations'].extend([
            "Q-Learning con GPU: Beneficio limitado (operaciones de tabla)",
            "Entorno paralelo: GPU puede acelerar simulaciones complejas",
            "Batch processing: Agrupar evaluaciones para usar GPU eficientemente"
        ])
    elif gpu_info['mps_available']:
        gpu_info['recommendations'].extend([
            "MPS puede acelerar c√°lculos matem√°ticos intensivos",
            "Mejor para operaciones vectorizadas que para Q-Learning discreto",
            "Considerar paralelizaci√≥n CPU como alternativa principal"
        ])
    else:
        gpu_info['recommendations'].extend([
            "Sin GPU disponible - usar paralelizaci√≥n CPU optimizada",
            "Ray multiprocessing ser√° m√°s efectivo que GPU para este problema",
            "Considerar usar instancia cloud con GPU si es necesario"
        ])
    
    return gpu_info

def design_10k_episode_experiment():
    """Dise√±a distribuci√≥n eficiente de 10,000 episodios"""
    
    print("\n" + "="*80)
    print("üìä DISE√ëO PARA ~10,000 EPISODIOS")
    print("="*80)
    
    # Configuraciones posibles para llegar a ~10k episodios
    configs = [
        {
            "name": "Configuraci√≥n Balanceada",
            "description": "Balance entre exploraci√≥n y tiempo",
            "schemes": 1,  # Solo Media
            "agents": 1,   # Solo Q-Learning
            "hyperparameter_combinations": 16,  # 2√ó2√ó2√ó2 grid m√°s completo
            "episodes_per_combination": 200,    # Reducido pero suficiente
            "final_training": 3000,
            "final_evaluation": 500,
            "total_episodes": 16 * 200 + 3000 + 500
        },
        {
            "name": "Configuraci√≥n Exploratoria",
            "description": "M√°s exploraci√≥n de hiperpar√°metros",
            "schemes": 1,  # Solo Media
            "agents": 1,   # Solo Q-Learning
            "hyperparameter_combinations": 32,  # 2√ó2√ó2√ó2√ó2 grid expandido
            "episodes_per_combination": 150,    
            "final_training": 2000,
            "final_evaluation": 400,
            "total_episodes": 32 * 150 + 2000 + 400
        },
        {
            "name": "Configuraci√≥n Enfocada",
            "description": "Pocos hiperpar√°metros, m√°s entrenamiento",
            "schemes": 1,  # Solo Media
            "agents": 1,   # Solo Q-Learning
            "hyperparameter_combinations": 8,   # 2√ó2√ó2 grid simple
            "episodes_per_combination": 250,    
            "final_training": 4000,  # M√°s entrenamiento final
            "final_evaluation": 600,
            "total_episodes": 8 * 250 + 4000 + 600
        }
    ]
    
    print("üéØ OPCIONES DE CONFIGURACI√ìN:")
    for i, config in enumerate(configs, 1):
        print(f"\n{i}. {config['name']} ({config['total_episodes']:,} episodios)")
        print(f"   üìù {config['description']}")
        print(f"   üî¨ Hiperpar√°metros: {config['hyperparameter_combinations']} combinaciones √ó {config['episodes_per_combination']} eps")
        print(f"   üèãÔ∏è Entrenamiento final: {config['final_training']:,} episodios")
        print(f"   üìä Evaluaci√≥n final: {config['final_evaluation']:,} episodios")
        
        # Estimaci√≥n de tiempo
        episodes_per_minute = 60  # Estimaci√≥n optimista con paralelizaci√≥n
        estimated_minutes = config['total_episodes'] / episodes_per_minute
        print(f"   ‚è±Ô∏è  Tiempo estimado: {estimated_minutes:.0f} minutos ({estimated_minutes/60:.1f} horas)")
    
    return configs

def create_optimized_10k_config():
    """Crea configuraci√≥n optimizada para 10k episodios"""
    
    config = {
        "experiment_name": "FLAN_10K_OPTIMIZED",
        "description": "Experimento FLAN optimizado para ~10,000 episodios",
        "target_episodes": 10000,
        
        "discretization_schemes": [
            {
                "name": "Media",
                "altitude_bins": 25,
                "velocity_bins": 25,
                "target_alt_bins": 25,
                "runway_dist_bins": 25,
                "action_bins": 10,
                "justification": "Esquema balanceado - buen compromiso precisi√≥n/velocidad"
            }
        ],
        
        "hyperparameter_grid": {
            "learning_rate": [0.3, 0.4],           # 2 valores (mejores del an√°lisis)
            "discount_factor": [0.98, 0.99],       # 2 valores (altos para largo plazo)
            "epsilon": [0.2, 0.3],                 # 2 valores (exploraci√≥n balanceada)
            "use_double_q": [True],                 # 1 valor (siempre mejor)
            "use_reward_shaping": [True]            # 1 valor (siempre mejor)
        },
        
        "training_episodes": {
            "hyperparameter_search": 400,    # 8 combinaciones √ó 400 = 3,200
            "hyperparameter_evaluation": 50, # Incluido en los 400
            "final_training": 4500,           # Entrenamiento intensivo
            "final_evaluation": 800           # Evaluaci√≥n robusta
        },
        
        "parallelization": {
            "strategy": "ray_multiprocessing",
            "cpu_cores": "all_available",
            "max_concurrent_trials": 8,
            "batch_size": 2,
            "justification": "Ray m√°s eficiente que GPU para Q-Learning discreto"
        },
        
        "environment_strategy": {
            "hyperparameter_search": "MockDescentEnv",
            "final_training": "DescentEnv", 
            "justification": "Mock para velocidad en b√∫squeda, real para resultado final"
        },
        
        "gpu_considerations": {
            "q_learning_benefit": "BAJO - operaciones de tabla, no intensivas",
            "environment_benefit": "MEDIO - puede acelerar simulaciones complejas",
            "evaluation_benefit": "ALTO - paralelizaci√≥n masiva de evaluaciones",
            "recommendation": "CPU paralelizado es m√°s efectivo para este problema espec√≠fico"
        }
    }
    
    # Calcular episodios totales
    combinations = 2 * 2 * 2 * 1 * 1  # 8 combinaciones
    total_episodes = (combinations * 400) + 4500 + 800  # 8,500 episodios
    
    config["calculated_episodes"] = total_episodes
    config["estimated_time_minutes"] = total_episodes / 80  # ~80 episodios/minuto con optimizaciones
    
    return config

def main():
    """Funci√≥n principal del an√°lisis"""
    
    print("üéØ AN√ÅLISIS PARA EXPERIMENTO DE ~10,000 EPISODIOS")
    print("Evaluaci√≥n GPU vs CPU para Q-Learning")
    
    # Detectar capacidades GPU
    gpu_info = detect_gpu_capabilities()
    
    # Dise√±ar opciones de experimento
    configs = design_10k_episode_experiment()
    
    # Crear configuraci√≥n optimizada
    optimized_config = create_optimized_10k_config()
    
    # Evaluaci√≥n espec√≠fica de GPU para Q-Learning
    print("\n" + "="*80)
    print("‚ö° EVALUACI√ìN GPU PARA Q-LEARNING")
    print("="*80)
    
    print("üî¥ COMPONENTES CON BAJO BENEFICIO GPU:")
    print("   ‚Ä¢ Q-Table Updates: Operaciones de indexaci√≥n simple")
    print("   ‚Ä¢ State Discretization: C√°lculos b√°sicos de binning")
    print("   ‚Ä¢ Action Selection: B√∫squeda de m√°ximo en tabla peque√±a")
    
    print("\nüü° COMPONENTES CON BENEFICIO MEDIO GPU:")
    print("   ‚Ä¢ Environment Simulation: Depende de complejidad del simulador")
    print("   ‚Ä¢ Reward Calculation: Puede beneficiarse si hay muchas operaciones matem√°ticas")
    
    print("\nüü¢ COMPONENTES CON ALTO BENEFICIO GPU:")
    print("   ‚Ä¢ Batch Evaluation: 100+ evaluaciones simult√°neas")
    print("   ‚Ä¢ Hyperparameter Search: Entrenamientos paralelos independientes")
    
    print(f"\nüéØ RECOMENDACI√ìN PARA TU CASO:")
    print(f"   ‚Ä¢ Q-Learning discreto: CPU paralelizado es M√ÅS eficiente")
    print(f"   ‚Ä¢ Usa Ray multiprocessing en lugar de GPU")
    print(f"   ‚Ä¢ GPU √∫til solo si tienes 50+ agentes evalu√°ndose simult√°neamente")
    print(f"   ‚Ä¢ Para 10k episodios: CPU optimizado ser√° 2-3x m√°s r√°pido que GPU")
    
    # Guardar configuraci√≥n
    with open('flan_10k_config.json', 'w') as f:
        json.dump(optimized_config, f, indent=2)
    
    # Resumen final
    print("\n" + "="*80)
    print("üìã CONFIGURACI√ìN RECOMENDADA PARA 10K EPISODIOS")
    print("="*80)
    
    print(f"üìä DISTRIBUCI√ìN DE EPISODIOS:")
    print(f"   ‚Ä¢ B√∫squeda hiperpar√°metros: 8 combinaciones √ó 400 = 3,200")
    print(f"   ‚Ä¢ Entrenamiento final: 4,500 episodios")
    print(f"   ‚Ä¢ Evaluaci√≥n final: 800 episodios")
    print(f"   ‚Ä¢ TOTAL: {optimized_config['calculated_episodes']:,} episodios")
    
    print(f"\n‚è±Ô∏è  TIEMPO ESTIMADO:")
    print(f"   ‚Ä¢ Con CPU optimizado: {optimized_config['estimated_time_minutes']:.0f} minutos")
    print(f"   ‚Ä¢ Con GPU (menos eficiente): ~{optimized_config['estimated_time_minutes']*1.5:.0f} minutos")
    
    print(f"\nüöÄ ESTRATEGIA RECOMENDADA:")
    print(f"   ‚Ä¢ Usar Ray multiprocessing (CPU)")
    print(f"   ‚Ä¢ Todos los cores disponibles")
    print(f"   ‚Ä¢ MockDescentEnv para b√∫squeda r√°pida")
    print(f"   ‚Ä¢ DescentEnv real para entrenamiento final")
    
    print(f"\nüõ†Ô∏è  ARCHIVO GENERADO:")
    print(f"   ‚Ä¢ flan_10k_config.json - Configuraci√≥n optimizada")
    
    print(f"\nüí° GPU ALTERNATIVA:")
    print(f"   ‚Ä¢ Si quieres probar GPU: usar para evaluaci√≥n masiva √∫nicamente")
    print(f"   ‚Ä¢ Mantener entrenamiento Q-Learning en CPU")
    print(f"   ‚Ä¢ Considerar GPU solo si tienes 100+ agentes en paralelo")
    
    print("\n" + "="*80)

if __name__ == "__main__":
    main() 