#!/usr/bin/env python3
"""
üöÄ OPTIMIZADOR ULTRA PERFORMANCE - M√ÅXIMO PROCESAMIENTO POSIBLE
Sistema que usa TODA la potencia de procesamiento disponible para optimizaci√≥n masiva
"""

import numpy as np
import time
import os
import psutil
import json
import pickle
from pathlib import Path
from datetime import datetime
from contextlib import redirect_stdout, redirect_stderr
from typing import Dict, List, Any, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# Paralelizaci√≥n masiva
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
import asyncio
import threading
from queue import Queue
import gc

# Detectar recursos del sistema
def detectar_recursos_sistema():
    """Detecta TODOS los recursos disponibles del sistema"""
    info = {
        'cpu_cores_fisicos': psutil.cpu_count(logical=False) or 1,
        'cpu_cores_logicos': psutil.cpu_count(logical=True) or 1,
        'ram_total_gb': psutil.virtual_memory().total / (1024**3),
        'ram_disponible_gb': psutil.virtual_memory().available / (1024**3),
        'cpu_freq_max': psutil.cpu_freq().max if psutil.cpu_freq() else 3000,
    }
    
    # Detectar GPU si est√° disponible
    try:
        import torch
        if torch.cuda.is_available():
            info['gpu_disponible'] = True
            info['gpu_count'] = torch.cuda.device_count()
            info['gpu_memory_gb'] = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        else:
            info['gpu_disponible'] = False
    except ImportError:
        info['gpu_disponible'] = False
    
    return info

class OptimizadorUltraPerformance:
    """
    Optimizador que usa TODO el procesamiento disponible
    - Paralelizaci√≥n masiva multinivel
    - Batch processing optimizado
    - Gesti√≥n inteligente de memoria
    - Paralelizaci√≥n anidada
    """
    
    def __init__(self, objetivo_mejora: float = 10.0):
        self.objetivo_mejora = objetivo_mejora
        self.recursos = detectar_recursos_sistema()
        self.configurar_paralelizacion_masiva()
        
        # Configuraciones din√°micas de episodios
        self.episodios_rapido = 200        # Para exploraci√≥n inicial
        self.episodios_medio = 1000        # Para candidatos prometedores  
        self.episodios_intensivo = 4000    # Para validaci√≥n final
        
        # Historial y tracking
        self.historial_experimentos = []
        self.mejor_score_historico = -np.inf
        self.baseline_score = -np.inf
        
        print("üöÄ OPTIMIZADOR ULTRA PERFORMANCE INICIALIZADO")
        print("="*80)
        self._mostrar_recursos_sistema()
        
    def configurar_paralelizacion_masiva(self):
        """Configura paralelizaci√≥n masiva usando TODOS los recursos"""
        # CPU: Usar TODOS los cores l√≥gicos disponibles
        self.max_workers_cpu = self.recursos['cpu_cores_logicos']
        
        # Para procesos intensivos: usar cores f√≠sicos
        self.max_workers_intensivos = self.recursos['cpu_cores_fisicos']
        
        # Para tareas I/O: usar m√°s workers que cores (2x)
        self.max_workers_io = self.recursos['cpu_cores_logicos'] * 2
        
        # Batch sizes optimizados bas√°ndose en RAM
        ram_gb = self.recursos['ram_disponible_gb']
        if ram_gb > 16:
            self.batch_size_grande = 32
            self.batch_size_medio = 16
        elif ram_gb > 8:
            self.batch_size_grande = 16
            self.batch_size_medio = 8
        else:
            self.batch_size_grande = 8
            self.batch_size_medio = 4
            
        print(f"‚ö° CONFIGURACI√ìN PARALELIZACI√ìN MASIVA:")
        print(f"   ‚Ä¢ Workers CPU intensivos: {self.max_workers_intensivos}")
        print(f"   ‚Ä¢ Workers CPU general: {self.max_workers_cpu}")
        print(f"   ‚Ä¢ Workers I/O: {self.max_workers_io}")
        print(f"   ‚Ä¢ Batch size grande: {self.batch_size_grande}")
        print(f"   ‚Ä¢ Batch size medio: {self.batch_size_medio}")
    
    def _mostrar_recursos_sistema(self):
        """Muestra informaci√≥n detallada de recursos del sistema"""
        print(f"üñ•Ô∏è  RECURSOS DEL SISTEMA:")
        print(f"   ‚Ä¢ CPU F√≠sicos: {self.recursos['cpu_cores_fisicos']} cores")
        print(f"   ‚Ä¢ CPU L√≥gicos: {self.recursos['cpu_cores_logicos']} cores")
        print(f"   ‚Ä¢ RAM Total: {self.recursos['ram_total_gb']:.1f} GB")
        print(f"   ‚Ä¢ RAM Disponible: {self.recursos['ram_disponible_gb']:.1f} GB")
        print(f"   ‚Ä¢ CPU Freq Max: {self.recursos['cpu_freq_max']:.0f} MHz")
        
        if self.recursos['gpu_disponible']:
            print(f"   ‚Ä¢ GPU: ‚úÖ {self.recursos['gpu_count']} dispositivos")
            print(f"   ‚Ä¢ GPU Memory: {self.recursos['gpu_memory_gb']:.1f} GB")
        else:
            print(f"   ‚Ä¢ GPU: ‚ùå No disponible")
            
        print(f"   üéØ ESTRATEGIA: Paralelizaci√≥n masiva CPU + optimizaci√≥n memoria")
    
    def cargar_historial_completo(self):
        """Carga historial de experimentos previos para an√°lisis retroactivo"""
        print("\nüìö CARGANDO HISTORIAL COMPLETO...")
        
        archivos_resultados = [
            'flan_results.json',
            'flan_results_10k.json', 
            'flan_results_express.json',
            'flan_results_196k_ultra.json',
            'mejoras_radicales_final_results.json',
            'mejoras_ultra_radicales_results.json',
            'optimizacion_exitosa_*.json',
            'mejor_intento_*.json'
        ]
        
        experimentos_cargados = 0
        scores_historicos = []
        
        for patron in archivos_resultados:
            if '*' in patron:
                # Buscar archivos con patr√≥n
                archivos = list(Path('.').glob(patron))
            else:
                archivos = [Path(patron)] if Path(patron).exists() else []
            
            for archivo in archivos:
                try:
                    with open(archivo, 'r') as f:
                        data = json.load(f)
                    
                    # Extraer experimentos del archivo
                    experimentos = self._extraer_experimentos_de_json(str(archivo), data)
                    self.historial_experimentos.extend(experimentos)
                    experimentos_cargados += len(experimentos)
                    
                    # Recopilar scores
                    for exp in experimentos:
                        if 'score' in exp and exp['score'] > -900:
                            scores_historicos.append(exp['score'])
                    
                    print(f"   ‚úÖ {archivo.name}: {len(experimentos)} experimentos")
                    
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Error cargando {archivo}: {e}")
        
        if scores_historicos:
            self.mejor_score_historico = max(scores_historicos)
            self.baseline_score = np.median(scores_historicos)  # Usar mediana como baseline
            
            print(f"\nüìä AN√ÅLISIS HIST√ìRICO:")
            print(f"   ‚Ä¢ Experimentos totales: {experimentos_cargados}")
            print(f"   ‚Ä¢ Scores v√°lidos: {len(scores_historicos)}")
            print(f"   ‚Ä¢ Mejor score hist√≥rico: {self.mejor_score_historico:.2f}")
            print(f"   ‚Ä¢ Baseline (mediana): {self.baseline_score:.2f}")
            print(f"   ‚Ä¢ Objetivo nuevo: {self.mejor_score_historico + self.objetivo_mejora:.2f}")
            
            return True
        else:
            print("   ‚ö†Ô∏è No se encontraron scores v√°lidos. Iniciando desde cero.")
            self.mejor_score_historico = -999
            self.baseline_score = -999
            return False
    
    def _extraer_experimentos_de_json(self, archivo: str, data: Dict) -> List[Dict]:
        """Extrae experimentos de cualquier formato JSON"""
        experimentos = []
        
        try:
            # Formato est√°ndar FLAN
            if 'experiment_info' in data:
                for scheme_name, scheme_data in data.items():
                    if scheme_name == 'experiment_info':
                        continue
                    
                    if isinstance(scheme_data, dict):
                        for agent_type, agent_data in scheme_data.items():
                            if 'best_params' in agent_data and 'best_score' in agent_data:
                                experimento = {
                                    'archivo': archivo,
                                    'esquema': scheme_name,
                                    'agente': agent_type,
                                    'params': agent_data['best_params'],
                                    'score': agent_data['best_score'],
                                    'timestamp': os.path.getmtime(archivo)
                                }
                                experimentos.append(experimento)
            
            # Formato optimizaci√≥n exitosa
            elif 'params_exitosos' in data:
                experimento = {
                    'archivo': archivo,
                    'esquema': 'optimizacion_exitosa',
                    'agente': 'qlearning',
                    'params': data['params_exitosos'],
                    'score': data['score_final'],
                    'timestamp': data.get('timestamp', time.time())
                }
                experimentos.append(experimento)
            
            # Formato mejor intento
            elif 'params_mejor_intento' in data:
                experimento = {
                    'archivo': archivo,
                    'esquema': 'mejor_intento',
                    'agente': 'qlearning',
                    'params': data['params_mejor_intento'],
                    'score': data['score_final'],
                    'timestamp': data.get('timestamp', time.time())
                }
                experimentos.append(experimento)
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error extrayendo de {archivo}: {e}")
        
        return experimentos
    
    def generar_grid_hiperparametros_inteligente(self) -> List[Dict]:
        """Genera grid de hiperpar√°metros inteligente bas√°ndose en historial"""
        print("\nüß† GENERANDO GRID DE HIPERPAR√ÅMETROS INTELIGENTE...")
        
        if not self.historial_experimentos:
            # Sin historial: usar grid exploratorio amplio
            grid = self._grid_exploratorio_amplio()
            print(f"   ‚Ä¢ Modo: Exploraci√≥n amplia ({len(grid)} configuraciones)")
        else:
            # Con historial: usar an√°lisis inteligente
            grid = self._grid_basado_en_historial()
            print(f"   ‚Ä¢ Modo: Basado en historial ({len(grid)} configuraciones)")
        
        return grid
    
    def _grid_exploratorio_amplio(self) -> List[Dict]:
        """Grid exploratorio amplio para cuando no hay historial"""
        import itertools
        
        # Grid amplio para exploraci√≥n inicial
        param_grid = {
            'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9],
            'discount_factor': [0.95, 0.99, 0.995, 0.999],
            'epsilon': [0.1, 0.3, 0.5, 0.7, 0.9],
            'epsilon_decay': [0.9995, 0.9999, 0.99995, 0.99999],
            'use_double_q': [True, False],
            'use_reward_shaping': [True, False]
        }
        
        # Generar todas las combinaciones
        param_names = list(param_grid.keys())
        param_values = list(param_grid.values())
        
        grid = []
        for combination in itertools.product(*param_values):
            params = dict(zip(param_names, combination))
            grid.append(params)
        
        return grid
    
    def _grid_basado_en_historial(self) -> List[Dict]:
        """Grid inteligente bas√°ndose en mejores resultados hist√≥ricos"""
        # Obtener los mejores experimentos hist√≥ricos
        experimentos_ordenados = sorted(
            self.historial_experimentos,
            key=lambda x: x.get('score', -999),
            reverse=True
        )
        
        mejores_experimentos = experimentos_ordenados[:10]  # Top 10
        
        print(f"   üìä Analizando top {len(mejores_experimentos)} experimentos hist√≥ricos:")
        for i, exp in enumerate(mejores_experimentos[:5], 1):
            print(f"      {i}. Score: {exp['score']:.2f} - {exp.get('agente', 'unknown')}")
        
        # Extraer rangos de par√°metros prometedores
        learning_rates = [exp['params'].get('learning_rate', 0.1) for exp in mejores_experimentos if 'params' in exp]
        discount_factors = [exp['params'].get('discount_factor', 0.99) for exp in mejores_experimentos if 'params' in exp]
        epsilons = [exp['params'].get('epsilon', 0.3) for exp in mejores_experimentos if 'params' in exp]
        
        # Generar variaciones inteligentes alrededor de los mejores
        grid = []
        
        # 1. Mejores configuraciones exactas
        for exp in mejores_experimentos[:5]:
            if 'params' in exp:
                grid.append(exp['params'].copy())
        
        # 2. Variaciones alrededor de los mejores learning rates
        if learning_rates:
            best_lr = np.mean(learning_rates)
            for variation in [-0.2, -0.1, 0, 0.1, 0.2]:
                new_lr = np.clip(best_lr + variation, 0.01, 0.99)
                
                config = {
                    'learning_rate': new_lr,
                    'discount_factor': np.mean(discount_factors) if discount_factors else 0.99,
                    'epsilon': np.mean(epsilons) if epsilons else 0.3,
                    'epsilon_decay': 0.9999,
                    'use_double_q': True,
                    'use_reward_shaping': True
                }
                grid.append(config)
        
        # 3. Configuraciones h√≠bridas ultra-agresivas
        configuraciones_agresivas = [
            {'learning_rate': 0.95, 'discount_factor': 0.99999, 'epsilon': 0.98, 'epsilon_decay': 0.999995, 'use_double_q': True, 'use_reward_shaping': True},
            {'learning_rate': 0.8, 'discount_factor': 0.999, 'epsilon': 0.9, 'epsilon_decay': 0.9999, 'use_double_q': True, 'use_reward_shaping': True},
            {'learning_rate': 0.7, 'discount_factor': 0.9999, 'epsilon': 0.85, 'epsilon_decay': 0.99995, 'use_double_q': True, 'use_reward_shaping': True},
        ]
        grid.extend(configuraciones_agresivas)
        
        return grid
    
    def ejecutar_experimento_masivo_paralelo(self, grid_hiperparametros: List[Dict]) -> Dict:
        """Ejecuta experimentos masivos en paralelo usando TODA la potencia de procesamiento"""
        print(f"\nüöÄ EJECUTANDO EXPERIMENTOS MASIVOS EN PARALELO")
        print(f"   üìä Configuraciones a probar: {len(grid_hiperparametros)}")
        print(f"   ‚ö° Workers paralelos: {self.max_workers_cpu}")
        print("="*60)
        
        start_time = time.time()
        
        # Fase 1: Evaluaci√≥n r√°pida masiva (200 episodios cada uno)
        print("üî• FASE 1: EVALUACI√ìN R√ÅPIDA MASIVA")
        candidatos_prometedores = self._fase_evaluacion_rapida(grid_hiperparametros)
        
        # Fase 2: Evaluaci√≥n intermedia de candidatos prometedores (1000 episodios)
        print(f"\nüéØ FASE 2: EVALUACI√ìN INTERMEDIA ({len(candidatos_prometedores)} candidatos)")
        candidatos_finales = self._fase_evaluacion_intermedia(candidatos_prometedores)
        
        # Fase 3: Evaluaci√≥n intensiva final (4000 episodios)
        print(f"\nüèÜ FASE 3: EVALUACI√ìN INTENSIVA FINAL ({len(candidatos_finales)} candidatos)")
        resultado_final = self._fase_evaluacion_intensiva(candidatos_finales)
        
        tiempo_total = time.time() - start_time
        
        print(f"\n‚úÖ EXPERIMENTO MASIVO COMPLETADO")
        print(f"   ‚è±Ô∏è Tiempo total: {tiempo_total/60:.1f} minutos")
        print(f"   üéØ Mejor resultado: {resultado_final['score']:.2f}")
        print(f"   üí™ Configuraciones probadas: {len(grid_hiperparametros)}")
        
        return resultado_final
    
    def _fase_evaluacion_rapida(self, grid_configs: List[Dict]) -> List[Dict]:
        """Fase 1: Evaluaci√≥n r√°pida masiva con paralelizaci√≥n extrema"""
        print(f"   üìä Evaluando {len(grid_configs)} configuraciones con {self.episodios_rapido} episodios cada una")
        
        # Preparar tareas para paralelizaci√≥n masiva
        tareas = []
        for i, config in enumerate(grid_configs):
            tarea = {
                'id': i,
                'config': config,
                'episodios': self.episodios_rapido,
                'evaluacion_episodes': 50
            }
            tareas.append(tarea)
        
        # Ejecutar en lotes para optimizar memoria
        resultados = []
        batch_size = self.batch_size_grande
        
        for i in range(0, len(tareas), batch_size):
            batch = tareas[i:i + batch_size]
            print(f"      üîÑ Batch {i//batch_size + 1}/{(len(tareas)-1)//batch_size + 1}: {len(batch)} configuraciones")
            
            # Paralelizaci√≥n masiva del batch
            batch_results = self._ejecutar_batch_paralelo(batch)
            resultados.extend(batch_results)
            
            # Limpiar memoria
            gc.collect()
        
        # Seleccionar top candidatos (30% mejores)
        resultados_validos = [r for r in resultados if r['score'] > -900]
        resultados_ordenados = sorted(resultados_validos, key=lambda x: x['score'], reverse=True)
        
        num_candidatos = max(5, len(resultados_ordenados) // 3)  # Top 30%
        candidatos_prometedores = resultados_ordenados[:num_candidatos]
        
        print(f"   ‚úÖ Fase 1 completada. Candidatos prometedores: {len(candidatos_prometedores)}")
        for i, candidato in enumerate(candidatos_prometedores[:5], 1):
            print(f"      {i}. Score: {candidato['score']:.2f}")
        
        return candidatos_prometedores
    
    def _fase_evaluacion_intermedia(self, candidatos: List[Dict]) -> List[Dict]:
        """Fase 2: Evaluaci√≥n intermedia de candidatos prometedores"""
        print(f"   üìä Re-evaluando candidatos con {self.episodios_medio} episodios cada uno")
        
        # Actualizar configuraciones para evaluaci√≥n intermedia
        tareas = []
        for i, candidato in enumerate(candidatos):
            tarea = {
                'id': i,
                'config': candidato['config'],
                'episodios': self.episodios_medio,
                'evaluacion_episodes': 200
            }
            tareas.append(tarea)
        
        # Ejecutar con paralelizaci√≥n intensiva (menos workers para m√°s recursos por tarea)
        resultados = self._ejecutar_batch_paralelo(tareas, workers=self.max_workers_intensivos)
        
        # Seleccionar top candidatos finales (50% mejores)
        resultados_validos = [r for r in resultados if r['score'] > -900]
        resultados_ordenados = sorted(resultados_validos, key=lambda x: x['score'], reverse=True)
        
        num_finales = max(2, len(resultados_ordenados) // 2)  # Top 50%
        candidatos_finales = resultados_ordenados[:num_finales]
        
        print(f"   ‚úÖ Fase 2 completada. Candidatos finales: {len(candidatos_finales)}")
        for i, candidato in enumerate(candidatos_finales, 1):
            print(f"      {i}. Score: {candidato['score']:.2f}")
        
        return candidatos_finales
    
    def _fase_evaluacion_intensiva(self, candidatos: List[Dict]) -> Dict:
        """Fase 3: Evaluaci√≥n intensiva final con m√°ximos recursos"""
        print(f"   üìä Evaluaci√≥n intensiva con {self.episodios_intensivo} episodios cada uno")
        
        # Configurar para m√°xima precisi√≥n
        tareas = []
        for i, candidato in enumerate(candidatos):
            tarea = {
                'id': i,
                'config': candidato['config'],
                'episodios': self.episodios_intensivo,
                'evaluacion_episodes': 800
            }
            tareas.append(tarea)
        
        # Ejecutar con recursos m√°ximos
        resultados = self._ejecutar_batch_paralelo(tareas, workers=min(len(tareas), self.max_workers_intensivos))
        
        # Seleccionar el mejor absoluto
        mejor_resultado = max(resultados, key=lambda x: x['score'])
        
        print(f"   üèÜ Mejor configuraci√≥n final:")
        print(f"      ‚Ä¢ Score: {mejor_resultado['score']:.2f}")
        print(f"      ‚Ä¢ Config: {mejor_resultado['config']}")
        
        return mejor_resultado
    
    def _ejecutar_batch_paralelo(self, tareas: List[Dict], workers: int = None) -> List[Dict]:
        """Ejecuta un batch de tareas en paralelo masivo"""
        if workers is None:
            workers = self.max_workers_cpu
        
        resultados = []
        
        try:
            with ProcessPoolExecutor(max_workers=workers) as executor:
                # Enviar todas las tareas
                future_to_tarea = {
                    executor.submit(ejecutar_experimento_individual, tarea): tarea 
                    for tarea in tareas
                }
                
                # Recopilar resultados
                for future in as_completed(future_to_tarea):
                    tarea = future_to_tarea[future]
                    try:
                        resultado = future.result(timeout=300)  # 5 min timeout
                        resultados.append(resultado)
                        
                        print(f"         ‚úÖ Config {tarea['id']}: {resultado['score']:.2f}")
                        
                    except Exception as e:
                        print(f"         ‚ùå Config {tarea['id']}: Error - {e}")
                        # Agregar resultado fallido
                        resultados.append({
                            'id': tarea['id'],
                            'config': tarea['config'],
                            'score': -999,
                            'error': str(e)
                        })
        
        except Exception as e:
            print(f"   ‚ùå Error en paralelizaci√≥n: {e}")
        
        return resultados
    
    def optimizar_hasta_objetivo(self) -> Optional[Dict]:
        """Optimiza continuamente hasta alcanzar el objetivo"""
        print(f"\nüéØ OPTIMIZACI√ìN CONTINUA HASTA OBJETIVO +{self.objetivo_mejora}")
        print("="*80)
        
        # Cargar historial
        self.cargar_historial_completo()
        
        # Calcular objetivo
        objetivo_score = self.mejor_score_historico + self.objetivo_mejora
        print(f"   üìä Score objetivo: {objetivo_score:.2f}")
        print(f"   üìà Mejora requerida: +{self.objetivo_mejora:.2f}")
        
        # Iteraciones de optimizaci√≥n
        max_iteraciones = 10
        for iteracion in range(max_iteraciones):
            print(f"\nüîÑ ITERACI√ìN {iteracion + 1}/{max_iteraciones}")
            print("-" * 60)
            
            # Generar grid inteligente
            grid = self.generar_grid_hiperparametros_inteligente()
            
            # Ejecutar experimentos masivos
            mejor_resultado = self.ejecutar_experimento_masivo_paralelo(grid)
            
            # Verificar si se alcanz√≥ el objetivo
            mejora_conseguida = mejor_resultado['score'] - self.baseline_score
            
            print(f"\nüìä RESULTADO ITERACI√ìN {iteracion + 1}:")
            print(f"   ‚Ä¢ Score conseguido: {mejor_resultado['score']:.2f}")
            print(f"   ‚Ä¢ Mejora conseguida: +{mejora_conseguida:.2f}")
            print(f"   ‚Ä¢ Objetivo era: +{self.objetivo_mejora:.2f}")
            
            # Actualizar historial
            self.historial_experimentos.append({
                'archivo': 'optimizacion_ultra_performance',
                'esquema': 'ultra_performance',
                'agente': 'qlearning',
                'params': mejor_resultado['config'],
                'score': mejor_resultado['score'],
                'iteracion': iteracion + 1,
                'timestamp': time.time()
            })
            
            if mejor_resultado['score'] > self.mejor_score_historico:
                self.mejor_score_historico = mejor_resultado['score']
            
            # Verificar objetivo
            if mejora_conseguida >= self.objetivo_mejora:
                print(f"\nüèÜ ¬°OBJETIVO ALCANZADO!")
                print(f"   ‚Ä¢ Iteraciones necesarias: {iteracion + 1}")
                print(f"   ‚Ä¢ Mejora total: +{mejora_conseguida:.2f}")
                
                self._guardar_resultado_exitoso(mejor_resultado, iteracion + 1)
                return mejor_resultado
        
        print(f"\n‚ö†Ô∏è Objetivo no alcanzado en {max_iteraciones} iteraciones")
        print(f"   ‚Ä¢ Mejor resultado: {self.mejor_score_historico:.2f}")
        print(f"   ‚Ä¢ Mejora conseguida: +{self.mejor_score_historico - self.baseline_score:.2f}")
        
        return mejor_resultado if 'mejor_resultado' in locals() else None
    
    def _guardar_resultado_exitoso(self, resultado: Dict, iteraciones: int):
        """Guarda resultado exitoso con detalles completos"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        resultado_completo = {
            'exito': True,
            'timestamp': timestamp,
            'objetivo_mejora': self.objetivo_mejora,
            'iteraciones_necesarias': iteraciones,
            'baseline_score': self.baseline_score,
            'score_final': resultado['score'],
            'mejora_conseguida': resultado['score'] - self.baseline_score,
            'config_exitosa': resultado['config'],
            'recursos_sistema': self.recursos,
            'paralelizacion_usada': {
                'workers_cpu': self.max_workers_cpu,
                'workers_intensivos': self.max_workers_intensivos,
                'batch_sizes': {
                    'grande': self.batch_size_grande,
                    'medio': self.batch_size_medio
                }
            }
        }
        
        filename = f"ultra_performance_exitoso_{timestamp}.json"
        with open(filename, 'w') as f:
            json.dump(resultado_completo, f, indent=2)
        
        print(f"   üíæ Resultado guardado en: {filename}")

def ejecutar_experimento_individual(tarea: Dict) -> Dict:
    """Funci√≥n para ejecutar un experimento individual (paralelizable)"""
    try:
        # Importar dentro de la funci√≥n para evitar problemas de paralelizaci√≥n
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        
        from flan_qlearning_solution import (
            DescentEnv, MockDescentEnv, DiscretizationScheme,
            QLearningAgent, QLearningTrainer, PerformanceEvaluator,
            BLUESKY_AVAILABLE, MOCK_AVAILABLE
        )
        
        # Suprimir salida para paralelizaci√≥n limpia
        with open(os.devnull, 'w') as devnull:
            with redirect_stdout(devnull), redirect_stderr(devnull):
                # Crear entorno
                if BLUESKY_AVAILABLE:
                    env = DescentEnv(render_mode=None)
                elif MOCK_AVAILABLE:
                    env = MockDescentEnv(render_mode=None)
                else:
                    raise ImportError("No hay entornos disponibles")
                
                # Configuraci√≥n optimizada
                discretization = DiscretizationScheme("UltraPerf", 25, 20, 20, 20, 12)
                
                # Crear y entrenar agente
                agent = QLearningAgent(discretization, **tarea['config'])
                trainer = QLearningTrainer(env, agent, discretization)
                
                # Entrenamiento
                training_rewards = trainer.train(episodes=tarea['episodios'], verbose=False)
                
                # Evaluaci√≥n
                evaluator = PerformanceEvaluator(env, agent, discretization)
                eval_results = evaluator.evaluate_multiple_episodes(
                    num_episodes=tarea['evaluacion_episodes']
                )
                
                # Calcular score
                score = np.mean(eval_results['total_rewards'])
                
                env.close()
                
                return {
                    'id': tarea['id'],
                    'config': tarea['config'],
                    'score': score,
                    'episodios_entrenamiento': tarea['episodios'],
                    'episodios_evaluacion': tarea['evaluacion_episodes'],
                    'training_final_avg': np.mean(training_rewards[-100:]) if len(training_rewards) >= 100 else np.mean(training_rewards),
                    'eval_std': np.std(eval_results['total_rewards'])
                }
                
    except Exception as e:
        return {
            'id': tarea.get('id', -1),
            'config': tarea.get('config', {}),
            'score': -999,
            'error': str(e)
        }

def main():
    """Funci√≥n principal para ejecutar optimizaci√≥n ultra performance"""
    print("üöÄ OPTIMIZADOR ULTRA PERFORMANCE")
    print("="*80)
    print("üí™ OBJETIVO: Usar TODA la potencia de procesamiento disponible")
    print("üéØ ESTRATEGIA: Paralelizaci√≥n masiva multinivel + optimizaci√≥n inteligente")
    print("="*80)
    
    # Configuraci√≥n del usuario
    objetivo_mejora = float(input("üìä Mejora objetivo (puntos): ") or "10")
    
    # Crear optimizador
    optimizador = OptimizadorUltraPerformance(objetivo_mejora=objetivo_mejora)
    
    # Confirmar recursos
    print(f"\nüî• ¬øPROCEDER CON PARALELIZACI√ìN MASIVA?")
    print(f"   ‚Ä¢ Se usar√°n {optimizador.max_workers_cpu} workers CPU")
    print(f"   ‚Ä¢ Esto puede sobrecargar el sistema temporalmente")
    
    confirm = input("¬øContinuar? (y/N): ")
    if confirm.lower() != 'y':
        print("‚ùå Operaci√≥n cancelada")
        return
    
    # Ejecutar optimizaci√≥n
    resultado = optimizador.optimizar_hasta_objetivo()
    
    if resultado:
        print(f"\nüéâ OPTIMIZACI√ìN ULTRA PERFORMANCE COMPLETADA")
        print(f"   Score final: {resultado['score']:.2f}")
        print(f"   Configuraci√≥n: {resultado['config']}")
    else:
        print(f"\n‚ö†Ô∏è No se alcanz√≥ el objetivo, pero se obtuvieron mejoras")

if __name__ == "__main__":
    main() 